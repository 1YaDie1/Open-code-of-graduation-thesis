{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08a3748b",
   "metadata": {},
   "source": [
    "# LSTM模型构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07b0223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 32, 64)            57600     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32, 128)           98816     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 205954 (804.51 KB)\n",
      "Trainable params: 205954 (804.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Activation, Dropout \n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(units=32, input_shape=(32, 1), return_sequences=False),\n",
    "    Dense(units=16, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    initial_lr = 0.001  # 初始学习率\n",
    "    decay_factor = 0.5  # 学习率衰减因子\n",
    "    decay_epochs = 5    # 学习率衰减的周期数\n",
    "    new_lr = initial_lr * (decay_factor ** (epoch // decay_epochs))\n",
    "    return new_lr\n",
    "\n",
    "# 定义学习率回调\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# 打印模型概况\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ebd57",
   "metadata": {},
   "source": [
    "## 导入可直接进行训练的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32978d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>第1个行为</th>\n",
       "      <th>第2个行为</th>\n",
       "      <th>第3个行为</th>\n",
       "      <th>第4个行为</th>\n",
       "      <th>第5个行为</th>\n",
       "      <th>第6个行为</th>\n",
       "      <th>第7个行为</th>\n",
       "      <th>第8个行为</th>\n",
       "      <th>第9个行为</th>\n",
       "      <th>...</th>\n",
       "      <th>第24个行为</th>\n",
       "      <th>第25个行为</th>\n",
       "      <th>第26个行为</th>\n",
       "      <th>第27个行为</th>\n",
       "      <th>第28个行为</th>\n",
       "      <th>第29个行为</th>\n",
       "      <th>第30个行为</th>\n",
       "      <th>第31个行为</th>\n",
       "      <th>第32个行为</th>\n",
       "      <th>逻辑风格</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>127</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>129</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>130</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>131</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  第1个行为  第2个行为  第3个行为  第4个行为  第5个行为  第6个行为  第7个行为  第8个行为  第9个行为  ...  \\\n",
       "0      0     11      1      3      8      7      5      3      8      9  ...   \n",
       "1      1     11      1      2      4      4      4      3      8      5  ...   \n",
       "2      2     11      1      3      8     11      5      2      3     11  ...   \n",
       "3      3     11      1      3      8      7      5      3      8      9  ...   \n",
       "4      4      8     11      1      2      4      4      4      2      3  ...   \n",
       "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  ...   \n",
       "895  127      8     11      1      3      8     10      5      2      4  ...   \n",
       "896  128      8     11      1      3      8     10      5      3      8  ...   \n",
       "897  129     11      8      1      3      8     11      5      2      7  ...   \n",
       "898  130     11      8      1      2      4      4      4      2      3  ...   \n",
       "899  131     11      1      2      4      4      4      2      8      7  ...   \n",
       "\n",
       "     第24个行为  第25个行为  第26个行为  第27个行为  第28个行为  第29个行为  第30个行为  第31个行为  第32个行为  \\\n",
       "0         5       2       8       7       0       0       0       0       0   \n",
       "1         7       5       7       0       0       0       0       0       0   \n",
       "2         8       6       0       0       0       0       0       0       0   \n",
       "3         3       7       5       4       3       0       0       0       0   \n",
       "4         3       9       5       3       0       0       0       0       0   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "895       2       3      11       5       4       7       0       0       0   \n",
       "896       5       2       3      11       5       3       0       0       0   \n",
       "897       5       3       8      11       5       3       0       0       0   \n",
       "898       5       3       7       8       5       7       0       0       0   \n",
       "899       3       7       5       2       8       3       0       0       0   \n",
       "\n",
       "     逻辑风格  \n",
       "0       2  \n",
       "1       2  \n",
       "2       2  \n",
       "3       1  \n",
       "4       2  \n",
       "..    ...  \n",
       "895     2  \n",
       "896     2  \n",
       "897     1  \n",
       "898     2  \n",
       "899     2  \n",
       "\n",
       "[900 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('./test.xlsx') # 需要训练哪个数据集，就把哪个数据集放到test中，这些数据在《可直接训练的数据当中》\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76360811",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.iloc[0:631,1:34]\n",
    "val_data = data.iloc[631:768,1:34]\n",
    "test_data = data.iloc[768:900,1:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b94b6c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据集\n",
    "X_train = train_data.iloc[:,0:32]\n",
    "y_train = train_data.iloc[:,32]-1 # 后面进行one-hot \n",
    "X_val = val_data.iloc[:,0:32]\n",
    "y_val= val_data.iloc[:,32]-1 # 后面进行one-hot \n",
    "X_test = test_data.iloc[:,0:32]\n",
    "y_test = test_data.iloc[:,32]-1 # 后面进行one-hot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83467a69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(631, 32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(631,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "888c853c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(137,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_val.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b7f1cf",
   "metadata": {},
   "source": [
    "## 数据训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3233140",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "53/53 [==============================] - 9s 51ms/step - loss: 0.5184 - accuracy: 0.7480 - val_loss: 0.5638 - val_accuracy: 0.7080 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.3159 - accuracy: 0.8605 - val_loss: 0.5566 - val_accuracy: 0.7591 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.3273 - accuracy: 0.8526 - val_loss: 0.5425 - val_accuracy: 0.7080 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 0.2640 - accuracy: 0.8748 - val_loss: 0.5689 - val_accuracy: 0.6934 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.2233 - accuracy: 0.8986 - val_loss: 0.4968 - val_accuracy: 0.7153 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.2186 - accuracy: 0.9081 - val_loss: 0.5598 - val_accuracy: 0.7299 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.2365 - accuracy: 0.9033 - val_loss: 0.5092 - val_accuracy: 0.6861 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.2066 - accuracy: 0.9017 - val_loss: 0.4314 - val_accuracy: 0.7226 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.2173 - accuracy: 0.9002 - val_loss: 0.5045 - val_accuracy: 0.6715 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1967 - accuracy: 0.9081 - val_loss: 0.5407 - val_accuracy: 0.6861 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.2069 - accuracy: 0.9017 - val_loss: 0.4463 - val_accuracy: 0.7007 - lr: 2.5000e-04\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1940 - accuracy: 0.9128 - val_loss: 0.4564 - val_accuracy: 0.6788 - lr: 2.5000e-04\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.1902 - accuracy: 0.9128 - val_loss: 0.4858 - val_accuracy: 0.6861 - lr: 2.5000e-04\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 0.1894 - accuracy: 0.9065 - val_loss: 0.4324 - val_accuracy: 0.7007 - lr: 2.5000e-04\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 2s 43ms/step - loss: 0.1871 - accuracy: 0.8986 - val_loss: 0.4418 - val_accuracy: 0.6934 - lr: 2.5000e-04\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 0.1793 - accuracy: 0.9097 - val_loss: 0.4790 - val_accuracy: 0.7007 - lr: 1.2500e-04\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 0.1819 - accuracy: 0.9065 - val_loss: 0.4565 - val_accuracy: 0.6861 - lr: 1.2500e-04\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 0.1900 - accuracy: 0.9002 - val_loss: 0.4118 - val_accuracy: 0.7591 - lr: 1.2500e-04\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 0.1800 - accuracy: 0.9097 - val_loss: 0.4981 - val_accuracy: 0.7007 - lr: 1.2500e-04\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 0.1835 - accuracy: 0.9097 - val_loss: 0.4423 - val_accuracy: 0.6788 - lr: 1.2500e-04\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.1773 - accuracy: 0.9097 - val_loss: 0.4392 - val_accuracy: 0.7153 - lr: 6.2500e-05\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.1784 - accuracy: 0.9033 - val_loss: 0.4397 - val_accuracy: 0.7153 - lr: 6.2500e-05\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 2s 39ms/step - loss: 0.1781 - accuracy: 0.9113 - val_loss: 0.4341 - val_accuracy: 0.7226 - lr: 6.2500e-05\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.1762 - accuracy: 0.9128 - val_loss: 0.4530 - val_accuracy: 0.6861 - lr: 6.2500e-05\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.1743 - accuracy: 0.9097 - val_loss: 0.4302 - val_accuracy: 0.7153 - lr: 6.2500e-05\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.1752 - accuracy: 0.9128 - val_loss: 0.4385 - val_accuracy: 0.6934 - lr: 3.1250e-05\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.1726 - accuracy: 0.9097 - val_loss: 0.4469 - val_accuracy: 0.6934 - lr: 3.1250e-05\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.1736 - accuracy: 0.9128 - val_loss: 0.4513 - val_accuracy: 0.6715 - lr: 3.1250e-05\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.1724 - accuracy: 0.9128 - val_loss: 0.4436 - val_accuracy: 0.7007 - lr: 3.1250e-05\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 0.1733 - accuracy: 0.9097 - val_loss: 0.4501 - val_accuracy: 0.6861 - lr: 3.1250e-05\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.1720 - accuracy: 0.9128 - val_loss: 0.4452 - val_accuracy: 0.6642 - lr: 1.5625e-05\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.1719 - accuracy: 0.9128 - val_loss: 0.4403 - val_accuracy: 0.7007 - lr: 1.5625e-05\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 0.1715 - accuracy: 0.9128 - val_loss: 0.4466 - val_accuracy: 0.6861 - lr: 1.5625e-05\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 0.1716 - accuracy: 0.9113 - val_loss: 0.4419 - val_accuracy: 0.7007 - lr: 1.5625e-05\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 0.1723 - accuracy: 0.9128 - val_loss: 0.4400 - val_accuracy: 0.7007 - lr: 1.5625e-05\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 2s 42ms/step - loss: 0.1709 - accuracy: 0.9144 - val_loss: 0.4417 - val_accuracy: 0.7007 - lr: 7.8125e-06\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 2s 47ms/step - loss: 0.1708 - accuracy: 0.9160 - val_loss: 0.4424 - val_accuracy: 0.6934 - lr: 7.8125e-06\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 3s 60ms/step - loss: 0.1709 - accuracy: 0.9128 - val_loss: 0.4447 - val_accuracy: 0.6861 - lr: 7.8125e-06\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 0.1707 - accuracy: 0.9160 - val_loss: 0.4427 - val_accuracy: 0.6934 - lr: 7.8125e-06\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1711 - accuracy: 0.9160 - val_loss: 0.4441 - val_accuracy: 0.6861 - lr: 7.8125e-06\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.1705 - accuracy: 0.9160 - val_loss: 0.4432 - val_accuracy: 0.6934 - lr: 3.9063e-06\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.1704 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 3.9063e-06\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.1704 - accuracy: 0.9160 - val_loss: 0.4442 - val_accuracy: 0.6861 - lr: 3.9063e-06\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 2s 43ms/step - loss: 0.1705 - accuracy: 0.9160 - val_loss: 0.4436 - val_accuracy: 0.6934 - lr: 3.9063e-06\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 2s 44ms/step - loss: 0.1705 - accuracy: 0.9160 - val_loss: 0.4448 - val_accuracy: 0.6861 - lr: 3.9063e-06\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1702 - accuracy: 0.9160 - val_loss: 0.4436 - val_accuracy: 0.6934 - lr: 1.9531e-06\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 0.1702 - accuracy: 0.9160 - val_loss: 0.4438 - val_accuracy: 0.6934 - lr: 1.9531e-06\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 2s 44ms/step - loss: 0.1704 - accuracy: 0.9160 - val_loss: 0.4439 - val_accuracy: 0.6934 - lr: 1.9531e-06\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 3s 55ms/step - loss: 0.1702 - accuracy: 0.9160 - val_loss: 0.4432 - val_accuracy: 0.6934 - lr: 1.9531e-06\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 2s 46ms/step - loss: 0.1704 - accuracy: 0.9160 - val_loss: 0.4437 - val_accuracy: 0.6934 - lr: 1.9531e-06\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.1701 - accuracy: 0.9160 - val_loss: 0.4437 - val_accuracy: 0.6934 - lr: 9.7656e-07\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 0.1701 - accuracy: 0.9160 - val_loss: 0.4435 - val_accuracy: 0.6934 - lr: 9.7656e-07\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.1702 - accuracy: 0.9160 - val_loss: 0.4437 - val_accuracy: 0.6934 - lr: 9.7656e-07\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1701 - accuracy: 0.9160 - val_loss: 0.4435 - val_accuracy: 0.6934 - lr: 9.7656e-07\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.1701 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 9.7656e-07\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1701 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 4.8828e-07\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1701 - accuracy: 0.9160 - val_loss: 0.4435 - val_accuracy: 0.6934 - lr: 4.8828e-07\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1701 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 4.8828e-07\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4435 - val_accuracy: 0.6934 - lr: 4.8828e-07\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1701 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 4.8828e-07\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 2.4414e-07\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4435 - val_accuracy: 0.6934 - lr: 2.4414e-07\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 2.4414e-07\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 2.4414e-07\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 2.4414e-07\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 1.2207e-07\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 1.2207e-07\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 1.2207e-07\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 1.2207e-07\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 1.2207e-07\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 6.1035e-08\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 6.1035e-08\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 6.1035e-08\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 6.1035e-08\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 6.1035e-08\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 3.0518e-08\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 3.0518e-08\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 3.0518e-08\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 3.0518e-08\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 3.0518e-08\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 1.5259e-08\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 1.5259e-08\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 1.5259e-08\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 1.5259e-08\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 1.5259e-08\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 7.6294e-09\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 7.6294e-09\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 7.6294e-09\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 7.6294e-09\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 7.6294e-09\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 3.8147e-09\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 3.8147e-09\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 3.8147e-09\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 3.8147e-09\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 3.8147e-09\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 1.9073e-09\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 1.9073e-09\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 1.9073e-09\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 1.9073e-09\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1700 - accuracy: 0.9160 - val_loss: 0.4434 - val_accuracy: 0.6934 - lr: 1.9073e-09\n"
     ]
    }
   ],
   "source": [
    "# 假设你已经准备好了 train_data 和 train_labels 数据\n",
    "\n",
    "# 进行标签的 one-hot 编码\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_encoded = to_categorical(y_train, num_classes=2)\n",
    "y_val_encoded = to_categorical(y_val, num_classes=2)\n",
    "# 训练模型\n",
    "batch_size = 12\n",
    "epochs = 100\n",
    "\n",
    "history = model.fit(X_train, y_train_encoded, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val_encoded), callbacks=[lr_scheduler])\n",
    "# history = model.fit(train_data, y_train_encoded, batch_size=batch_size, epochs=epochs, callbacks=[lr_scheduler])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_ai",
   "language": "python",
   "name": "py39_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
